{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fb3bkhPH7mf"
      },
      "source": [
        "# Task 1: Finding the most similar word\n",
        "\n",
        "The goal of this task is given a corpus find the most similar word for a provided word. As an example we will consider the `'bible-kjv.txt'`corpus where we are looking to find the word that is most similar to `god`. We consider two words similar if they appear in the same context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BL9jpIoH7mf"
      },
      "source": [
        "## a) Cleaning the input\n",
        "\n",
        "Write a function `get_valid_tokens(corpus, remove_stopwords=False)` that given a list of tokens returns a list of tokens that we consider valid for out task.\n",
        "\n",
        "An *invalid* token is a token that\n",
        "- is a punctuation mark (consider `string.puctuation`).\n",
        "- is entirely numeric digits (e.g. `\"123\"`)\n",
        "- optionally if `remove_stopwords=True` stopwords in the englisch language are also not considered valid tokens (use nltk's stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sajiMFagH7mg"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "puncts = string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7PqyK3_H7mg"
      },
      "outputs": [],
      "source": [
        "def get_valid_tokens(corpus, remove_stopwords=False):\n",
        "    ret = list(filter(lambda x: x not in puncts and re.fullmatch(\"[0-9]+\", x) == None, corpus))\n",
        "    if remove_stopwords:\n",
        "        ret = list(filter(lambda x: x not in stop_words, ret))\n",
        "    return [x.lower() for x in ret]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpZ-v6uAH7mg",
        "outputId": "1743404b-a5bc-4516-cdb9-edc1d45e1867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['the', 'king', 'james', 'bible', 'the', 'old', 'testament', 'of', 'the', 'king', 'james', 'bible', 'the', 'first', 'book', 'of', 'moses', 'called', 'genesis', 'in', 'the', 'beginning', 'god', 'created', 'the', 'heaven', 'and', 'the', 'earth', 'and', 'the', 'earth', 'was', 'without', 'form', 'and', 'void', 'and', 'darkness', 'was', 'upon', 'the', 'face', 'of', 'the', 'deep', 'and', 'the', 'spirit', 'of', 'god', 'moved']\n"
          ]
        }
      ],
      "source": [
        "l=[]\n",
        "for i, word in enumerate(get_valid_tokens(nltk.corpus.gutenberg.words('bible-kjv.txt'))):\n",
        "    l.append(word)\n",
        "    if i >50:\n",
        "        break\n",
        "print(l)\n",
        "#['the', 'king', 'james', 'bible', 'the', 'old', 'testament', 'of', 'the', 'king', 'james', 'bible', 'the', 'first', 'book', 'of', 'moses', 'called', 'genesis', 'in', 'the', 'beginning', 'god', 'created', 'the', 'heaven', 'and', 'the', 'earth', 'and', 'the', 'earth', 'was', 'without', 'form', 'and', 'void', 'and', 'darkness', 'was', 'upon', 'the', 'face', 'of', 'the', 'deep', 'and', 'the', 'spirit', 'of', 'god', 'moved']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr8V3MlFH7mh"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8apkIK8pH7mh"
      },
      "outputs": [],
      "source": [
        "def get_sorrounding_counts(corpus, context_size):\n",
        "    ret = {}\n",
        "    for i in range(len(corpus)):\n",
        "        word = corpus[i]\n",
        "        if (word not in ret):\n",
        "            ret[word] = Counter()\n",
        "        for j in range(1, context_size+1):\n",
        "            if (i+j < len(corpus)):\n",
        "                sur_word = corpus[i+j]\n",
        "                if (sur_word not in ret):\n",
        "                    ret[sur_word] = Counter()\n",
        "                ret[word][sur_word] += 1\n",
        "                ret[sur_word][word] += 1\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6MeTSQ7H7mh",
        "outputId": "1fe169e2-08c9-449e-d62a-f622c142723a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'hi': Counter({'james': 1}),\n",
              " 'james': Counter({'hi': 1, 'how': 1}),\n",
              " 'how': Counter({'james': 1, 'are': 2, 'catherine': 1}),\n",
              " 'are': Counter({'how': 2, 'you': 2}),\n",
              " 'you': Counter({'are': 2, 'hello': 1}),\n",
              " 'hello': Counter({'you': 1, 'catherine': 1}),\n",
              " 'catherine': Counter({'hello': 1, 'how': 1})}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "simple_text = ['hi', 'james', 'how', 'are', 'you', 'hello', 'catherine', 'how', 'are', 'you']\n",
        "get_sorrounding_counts(simple_text, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w3lyHRFH7mh",
        "outputId": "55e891de-ff27-409d-934d-1016195d3214"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'hi': Counter({'james': 1, 'how': 1}), 'james': Counter({'hi': 1, 'how': 1, 'are': 1}), 'how': Counter({'are': 2, 'you': 2, 'hi': 1, 'james': 1, 'hello': 1, 'catherine': 1}), 'are': Counter({'how': 2, 'you': 2, 'james': 1, 'hello': 1, 'catherine': 1}), 'you': Counter({'how': 2, 'are': 2, 'hello': 1, 'catherine': 1}), 'hello': Counter({'are': 1, 'you': 1, 'catherine': 1, 'how': 1}), 'catherine': Counter({'you': 1, 'hello': 1, 'how': 1, 'are': 1})}\n"
          ]
        }
      ],
      "source": [
        "print(get_sorrounding_counts(simple_text, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4BFPvPSH7mi",
        "outputId": "37186083-6c46-4f9e-d0b2-170353cdd7fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12579\n"
          ]
        }
      ],
      "source": [
        "# now for the bible corpus\n",
        "tokens = get_valid_tokens(nltk.corpus.gutenberg.words('bible-kjv.txt'), remove_stopwords=False)\n",
        "d=get_sorrounding_counts(tokens, 2)\n",
        "print(len(d)) #12579"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2UHw7GnH7mi",
        "outputId": "5f9a28dd-2722-46da-e624-1aa28ceb0957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({'and': 123, 'king': 63, 'of': 62, 'the': 49, 'to': 49, 'son': 37, 'had': 25, 's': 25, 'made': 24, 'all': 20, 'for': 19, 'unto': 19, 'which': 19, 'his': 17, 'that': 17, 'then': 16, 'in': 15, 'built': 12, 'said': 11, 'gave': 11, 'did': 9, 'a': 9, 'lord': 9, 'servants': 9, 'my': 8, 'sent': 8, 'solomon': 8, 'wisdom': 8, 'when': 8, 'saying': 7, 'thy': 7, 'he': 7, 'with': 7, 'was': 7, 'so': 7, 'told': 6, 'days': 6, 'came': 6, 'but': 5, 'out': 5, 'hiram': 5, 'work': 5, 'brought': 5, 'children': 5, 'is': 5, 'also': 4, 'servant': 4, 'make': 4, 'they': 4, 'because': 4, 'behold': 4, 'she': 4, 'wife': 4, 'reigned': 4, 'year': 4, 'israel': 4, 'stood': 4, 'time': 4, 'years': 4, 'her': 4, 'went': 4, 'nathan': 3, 'assuredly': 3, 'shall': 3, 'be': 3, 'hath': 3, 'than': 3, 'thee': 3, 'by': 3, 'appeared': 3, 'thou': 3, 'daughter': 3, 'from': 3, 'david': 3, 'cedar': 3, 'thus': 3, 'house': 3, 'before': 3, 'offered': 3, 'finished': 3, 'come': 3, 'heart': 3, 'horses': 3, 'father': 3, 'acts': 3, 'gold': 3, 'them': 3, 'proverbs': 3, 'ibhar': 2, 'name': 2, 'mother': 2, 'save': 2, 'on': 2, 'let': 2, 'sat': 2, 'upon': 2, 'altar': 2, 'hand': 2, 'loved': 2, 'offer': 2, 'over': 2, 'god': 2, 'i': 2, 'desire': 2, 'as': 2, 'raised': 2, 'levy': 2, 'threescore': 2, 'officers': 2, 'concerning': 2, 'it': 2, 'like': 2, 'assembled': 2, 'jerusalem': 2, 'spake': 2, 'pass': 2, 'cities': 2, 'desired': 2, 'no': 2, 'were': 2, 'burnt': 2, 'fame': 2, 'communed': 2, 'one': 2, 'two': 2, 'sought': 2, 'hear': 2, 'gathered': 2, 'abundance': 2, 'slept': 2, 'four': 2, 'temple': 2, 'called': 2, 'exceedingly': 2, 'up': 2, 'wherein': 2, 'people': 2, 'night': 2, 'presence': 2, 'rehoboam': 2, 'not': 2, 'song': 2, 'begat': 2, 'greater': 2, 'here': 2, 'porch': 2, 'men': 1, 'brother': 1, 'hast': 1, 'go': 1, 'host': 1, 'cause': 1, 'ye': 1, 'caused': 1, 'ride': 1, 'anointed': 1, 'sitteth': 1, 'better': 1, 'arose': 1, 'feareth': 1, 'lo': 1, 'swear': 1, 'sword': 1, 'if': 1, 'charged': 1, 'speak': 1, 'answered': 1, 'sware': 1, 'afflicted': 1, 'thrust': 1, 'joab': 1, 'benaiah': 1, 'shimei': 1, 'affinity': 1, 'offerings': 1, 'asked': 1, 'awoke': 1, 'tribute': 1, 'twelve': 1, 'merry': 1, 'served': 1, 'life': 1, 'provision': 1, 'forty': 1, 'table': 1, 'shore': 1, 'words': 1, 'trees': 1, 'chief': 1, 'builders': 1, 'reign': 1, 'overlaid': 1, 'building': 1, 'wrought': 1, 'zarthan': 1, 'left': 1, 'at': 1, 'egypt': 1, 'held': 1, 'second': 1, 'furnished': 1, 'given': 1, 'gezer': 1, 'store': 1, 'those': 1, 'seen': 1, 'drinking': 1, 'exceeded': 1, 'together': 1, 'many': 1, 'their': 1, 'gods': 1, 'clave': 1, 'old': 1, 'after': 1, 'ammonites': 1, 'evil': 1, 'build': 1, 'an': 1, 'angry': 1, 'forasmuch': 1, 'adversary': 1, 'hadad': 1, 'beside': 1, 'zereda': 1, 'millo': 1, 'valour': 1, 'seeing': 1, 'will': 1, 'ever': 1, 'therefore': 1, 'death': 1, 'jeroboam': 1, 'corruption': 1, 'bases': 1, 'sister': 1, 'singing': 1, 'until': 1, 'brass': 1, 'wherewith': 1, 'help': 1, 'chosen': 1, 'me': 1, 'congregation': 1, 'give': 1, 'priest': 1, 'themselves': 1, 'magnified': 1, 'honour': 1, 'chronicles': 1, 'fathers': 1, 'appear': 1, 'this': 1, 'chariots': 1, 'means': 1, 'determined': 1, 'kingdom': 1, 'numbered': 1, 'began': 1, 'things': 1, 'instructed': 1, 'zeredathah': 1, 'hands': 1, 'now': 1, 'moreover': 1, 'hallowed': 1, 'same': 1, 'kept': 1, 'into': 1, 'restored': 1, 'there': 1, 'prepared': 1, 'eziongeber': 1, 'ophir': 1, 'prove': 1, 'hard': 1, 'hid': 1, 'silver': 1, 'passed': 1, 'first': 1, 'nebat': 1, 'strong': 1, 'three': 1, 'writing': 1, 'wise': 1, 'curtains': 1, 'look': 1, 'himself': 1, 'found': 1, 'favour': 1, 'o': 1, 'must': 1, 'have': 1, 'urias': 1, 'roboam': 1, 'even': 1, 'you': 1, 'greatly': 1, 'accord': 1, 'jacob': 1, 'him': 1})\n"
          ]
        }
      ],
      "source": [
        "print(d['solomon'])\n",
        "#{'and': 123, 'king': 63, 'of': 62, 'the': 49, 'to': 49, 'son': 37, 'had': 25, 's': 25, 'made': 24, 'all': 20, 'for': 19, 'unto': 19, 'which': 19, 'his': 17, 'that': 17, 'then': 16, 'in': 15, 'built': 12, 'said': 11, 'gave': 11, 'did': 9, 'a': 9, 'lord': 9, 'servants': 9, 'my': 8, 'sent': 8, 'solomon': 8, 'wisdom': 8, 'when': 8, 'saying': 7, 'thy': 7, 'he': 7, 'with': 7, 'was': 7, 'so': 7, 'told': 6, 'days': 6, 'came': 6, 'but': 5, 'out': 5, 'hiram': 5, 'work': 5, 'brought': 5, 'children': 5, 'is': 5, 'also': 4, 'servant': 4, 'make': 4, 'they': 4, 'because': 4, 'behold': 4, 'she': 4, 'wife': 4, 'reigned': 4, 'year': 4, 'israel': 4, 'stood': 4, 'time': 4, 'years': 4, 'her': 4, 'went': 4, 'nathan': 3, 'assuredly': 3, 'shall': 3, 'be': 3, 'hath': 3, 'than': 3, 'thee': 3, 'by': 3, 'appeared': 3, 'thou': 3, 'daughter': 3, 'from': 3, 'david': 3, 'cedar': 3, 'thus': 3, 'house': 3, 'before': 3, 'offered': 3, 'finished': 3, 'come': 3, 'heart': 3, 'horses': 3, 'father': 3, 'acts': 3, 'gold': 3, 'them': 3, 'proverbs': 3, 'ibhar': 2, 'name': 2, 'mother': 2, 'save': 2, 'on': 2, 'let': 2, 'sat': 2, 'upon': 2, 'altar': 2, 'hand': 2, 'loved': 2, 'offer': 2, 'over': 2, 'god': 2, 'i': 2, 'desire': 2, 'as': 2, 'raised': 2, 'levy': 2, 'threescore': 2, 'officers': 2, 'concerning': 2, 'it': 2, 'like': 2, 'assembled': 2, 'jerusalem': 2, 'spake': 2, 'pass': 2, 'cities': 2, 'desired': 2, 'no': 2, 'were': 2, 'burnt': 2, 'fame': 2, 'communed': 2, 'one': 2, 'two': 2, 'sought': 2, 'hear': 2, 'gathered': 2, 'abundance': 2, 'slept': 2, 'four': 2, 'temple': 2, 'called': 2, 'exceedingly': 2, 'up': 2, 'wherein': 2, 'people': 2, 'night': 2, 'presence': 2, 'rehoboam': 2, 'not': 2, 'song': 2, 'begat': 2, 'greater': 2, 'here': 2, 'porch': 2, 'men': 1, 'brother': 1, 'hast': 1, 'go': 1, 'host': 1, 'cause': 1, 'ye': 1, 'caused': 1, 'ride': 1, 'anointed': 1, 'sitteth': 1, 'better': 1, 'arose': 1, 'feareth': 1, 'lo': 1, 'swear': 1, 'sword': 1, 'if': 1, 'charged': 1, 'speak': 1, 'answered': 1, 'sware': 1, 'afflicted': 1, 'thrust': 1, 'joab': 1, 'benaiah': 1, 'shimei': 1, 'affinity': 1, 'offerings': 1, 'asked': 1, 'awoke': 1, 'tribute': 1, 'twelve': 1, 'merry': 1, 'served': 1, 'life': 1, 'provision': 1, 'forty': 1, 'table': 1, 'shore': 1, 'words': 1, 'trees': 1, 'chief': 1, 'builders': 1, 'reign': 1, 'overlaid': 1, 'building': 1, 'wrought': 1, 'zarthan': 1, 'left': 1, 'at': 1, 'egypt': 1, 'held': 1, 'second': 1, 'furnished': 1, 'given': 1, 'gezer': 1, 'store': 1, 'those': 1, 'seen': 1, 'drinking': 1, 'exceeded': 1, 'together': 1, 'many': 1, 'their': 1, 'gods': 1, 'clave': 1, 'old': 1, 'after': 1, 'ammonites': 1, 'evil': 1, 'build': 1, 'an': 1, 'angry': 1, 'forasmuch': 1, 'adversary': 1, 'hadad': 1, 'beside': 1, 'zereda': 1, 'millo': 1, 'valour': 1, 'seeing': 1, 'will': 1, 'ever': 1, 'therefore': 1, 'death': 1, 'jeroboam': 1, 'corruption': 1, 'bases': 1, 'sister': 1, 'singing': 1, 'until': 1, 'brass': 1, 'wherewith': 1, 'help': 1, 'chosen': 1, 'me': 1, 'congregation': 1, 'give': 1, 'priest': 1, 'themselves': 1, 'magnified': 1, 'honour': 1, 'chronicles': 1, 'fathers': 1, 'appear': 1, 'this': 1, 'chariots': 1, 'means': 1, 'determined': 1, 'kingdom': 1, 'numbered': 1, 'began': 1, 'things': 1, 'instructed': 1, 'zeredathah': 1, 'hands': 1, 'now': 1, 'moreover': 1, 'hallowed': 1, 'same': 1, 'kept': 1, 'into': 1, 'restored': 1, 'there': 1, 'prepared': 1, 'eziongeber': 1, 'ophir': 1, 'prove': 1, 'hard': 1, 'hid': 1, 'silver': 1, 'passed': 1, 'first': 1, 'nebat': 1, 'strong': 1, 'three': 1, 'writing': 1, 'wise': 1, 'curtains': 1, 'look': 1, 'himself': 1, 'found': 1, 'favour': 1, 'o': 1, 'must': 1, 'have': 1, 'urias': 1, 'roboam': 1, 'even': 1, 'you': 1, 'greatly': 1, 'accord': 1, 'jacob': 1, 'him': 1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V42ZhHM0H7mi"
      },
      "source": [
        "## c) Keep top k words in context\n",
        "\n",
        "To reduce the size of the context we will only consider the most frequent words for each context. Therefor write a function `to_sets(count_dicts, k)` that for each word only keeps the `k` most frequent words of the context. Ties are resolved in favor of the lexicographically lower word (comes earlier when sorting the words). It returns a dict that maps words onto their context words (which are now stored in a set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH4Tjc75H7mi"
      },
      "outputs": [],
      "source": [
        "def to_sets(count_dicts, k):\n",
        "    ret = {}\n",
        "    for key in count_dicts:\n",
        "        dic = count_dicts[key]\n",
        "        sortedList = sorted(dic.most_common(), key=lambda pair: (-pair[1], pair[0]))\n",
        "        wordList = [pair[0] for pair in sortedList[:k]]\n",
        "        ret[key] = set(wordList)\n",
        "    return ret #{'lord' : {'hi'}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSSG6jvPH7mi",
        "outputId": "da22dab5-a163-4513-de2e-5916e3ca3f7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12579\n",
            "{'god', 'the', 'said', 'shall', 'thy', 'of', 'unto', 'is', 'and', 'for', 'before', 'in', 'my', 'to', 'saith', 'o', 'that', 'hath', 'i', 'which'}\n"
          ]
        }
      ],
      "source": [
        "d2 = to_sets(d,20)\n",
        "print(len(d2)) #12579\n",
        "print(d2['lord'])\n",
        "# {'said', 'is', 'my', 'unto', 'o', 'god', 'before', 'and', 'that', 'to', 'in', 'saith', 'i', 'hath', 'thy', 'shall', 'of', 'for', 'the', 'which'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P7mMH7aH7mi",
        "outputId": "b591b0c8-4525-4d3a-96c2-3035401838c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'hi': {'how', 'james'},\n",
              " 'james': {'are', 'hi'},\n",
              " 'how': {'are', 'you'},\n",
              " 'are': {'how', 'you'},\n",
              " 'you': {'are', 'how'},\n",
              " 'hello': {'are', 'catherine'},\n",
              " 'catherine': {'are', 'hello'}}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_sets(get_sorrounding_counts(simple_text, 2),2)\n",
        "\n",
        "#{'hi': {'how', 'james'},\n",
        "# 'james': {'are', 'hi'},\n",
        "# 'how': {'are', 'you'},\n",
        "# 'are': {'how', 'you'},\n",
        "# 'you': {'are', 'how'},\n",
        "# 'hello': {'are', 'catherine'},\n",
        "# 'catherine': {'are', 'hello'}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9h2vB49H7mj"
      },
      "source": [
        "## d)  Find the most similar word by context overlap\n",
        "\n",
        "Given a dictionary as obtained in the previous task, and a word that you are interested in, we will now find the most similar word by Jaccard index. The definition of the Jaccard similarity for two sets can be found on wikipedia.\n",
        "Write a function `find_most_similar_word(input_word, contexts)` that returns the most similar word to the input word (which is not the input word). It returns this word and the Jaccard similarity in this order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBtUxrQiH7mj"
      },
      "outputs": [],
      "source": [
        "def find_most_similar_word(input_word, contexts):\n",
        "    highScore = 0\n",
        "    highWord = ''\n",
        "    inputSet = contexts[input_word]\n",
        "    for word in contexts:\n",
        "        if word == input_word:\n",
        "            continue\n",
        "        wordSet = contexts[word]\n",
        "        union = wordSet.union(inputSet)\n",
        "        overlap = wordSet.intersection(inputSet)\n",
        "\n",
        "        score = len(overlap)/len(union)\n",
        "        if score > highScore:\n",
        "            highScore = score\n",
        "            highWord = word\n",
        "    return highWord, highScore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoHnXNFeH7mj",
        "outputId": "1c3cc986-fdb0-4404-9924-e3c1ce328786"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('lord', 0.6)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_most_similar_word('god', d2)\n",
        "# ('lord', 0.6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu-lAX_rH7mj",
        "outputId": "0d6650cd-675f-4617-f869-0c3a6ff80dc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('place', 0.5384615384615384)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_most_similar_word('land', d2)\n",
        "# ('place', 0.5384615384615384)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPastVu8H7mj",
        "outputId": "2ee94160-6ffb-411a-8638-69d1cc45960b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('ascending', 0.34615384615384615)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_most_similar_word('angel', d2)\n",
        "# ('ascending', 0.34615384615384615)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc-ni2RFH7mj"
      },
      "source": [
        "# Task 2: WordNet path similarity\n",
        "\n",
        "Reimplement the path similarity between two words in WordNet using the NLTK package. The path similarity between two words is given by\n",
        "$$\n",
        "\\frac{1}{1+d}\n",
        "$$\n",
        "where $d$ is the shortest path of any pair of their synsets.\n",
        "Obviously, do not use the pathsim function already implemented. From NLTK you should only use the `synsets`, `hypernyms` and `instance_hpyernyms` functions.\n",
        "\n",
        "Write a function `get_dist(w1, w2, wn_instance)` where w1, w2 are words as strings and wn is a wordnet instance that should be used. I.e. call `wn_instance.synsets()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7V6UobvH7mk"
      },
      "outputs": [],
      "source": [
        "def get_hypernyms(lemma, wn_instance, lvl):\n",
        "    hypernyms = []\n",
        "    for ss in lemma.hypernyms():\n",
        "        hypernyms.append([ss, lvl])\n",
        "        hypernyms.extend(get_hypernyms(ss, wn_instance, lvl+1))\n",
        "\n",
        "    return hypernyms\n",
        "\n",
        "def get_word_hypernyms(word, wn_instance):\n",
        "    hypernyms = []\n",
        "    for lemma in wn_instance.synsets(word):\n",
        "        new_hypes = get_hypernyms(lemma, wn_instance, 1)\n",
        "        for new_hype in new_hypes:\n",
        "            contains = False\n",
        "            for old_hype in hypernyms:\n",
        "                if old_hype[0] == new_hype[0]:\n",
        "                    contains = True\n",
        "                    old_hype[1] = min(old_hype[1], new_hype[1])\n",
        "            if contains == False:\n",
        "                hypernyms.append(new_hype)\n",
        "    return hypernyms\n",
        "\n",
        "#get_word_hypernyms(\"bank\", wn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcgE8VRoH7mk"
      },
      "outputs": [],
      "source": [
        "def get_dist(w1, w2, wn_instance):\n",
        "    path_distance = 0\n",
        "    w1_hypes = get_word_hypernyms(w1, wn_instance)\n",
        "    w2_hypes = get_word_hypernyms(w2, wn_instance)\n",
        "    for hype1 in w1_hypes:\n",
        "        for hype2 in w2_hypes:\n",
        "            if hype1[0] == hype2[0]:\n",
        "                if path_distance == 0:\n",
        "                    path_distance = hype1[1] + hype2[1]\n",
        "                elif hype1[1] + hype2[1] < path_distance:\n",
        "                    path_distance = hype1[1] + hype2[1]\n",
        "\n",
        "    return 1/(1+path_distance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-Yi2yiTH7mk",
        "outputId": "3d854758-c2fe-4d9b-e975-93bc6287f4ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.08333333333333333\n",
            "0.14285714285714285\n",
            "0.25\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "#nltk.download(\"wordnet\")\n",
        "print(get_dist(\"bank\", \"coin\", wn)) # 0.08333333333333333\n",
        "print(get_dist(\"bank\", \"money\",wn)) # 0.14285714285714285\n",
        "print(get_dist(\"bank\", \"flood\",wn)) # 0.25\n",
        "\n",
        "# Think about why bank might be most similar to flood according to this metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V8NbbDJH7mk"
      },
      "source": [
        "# Task 3: Markov chains\n",
        "\n",
        "In this task we are looking to utilize the idea of Markov models and ngrams to solve different tasks. Throughout this task we will define a single class with different functions. You can certainly reuse the functions from earlier tasks. Whenever I use the term past, I mean an ngram represented as a tuple of strings.\n",
        "\n",
        "## a) Collecting the counts\n",
        "Write a function `process_corpus` that takes a corpus (as an iterator of strings) and collects for each the \"past\" of length `order` the count that a word follows this past.\n",
        "Remember that we will need these counts for the conditional probabilities: `P(word | past)`.\n",
        "Additionally also return the entire vocabulary (i.e. all tokens that are in the corpus).\n",
        "\n",
        "## b) Conditional probabilities\n",
        "Write a function `transition_prob(self, past, word)` that takes the past (a tuple of strings) and a word as input and returns the conditional probability that the word follows that past. Thereby use the laplace correction.\n",
        "If the past has never been observed return 1/size_of_vocabulary.\n",
        "\n",
        "## c) Most likely word\n",
        "Write a function that given a past returns the most likely word that comes next as a list of strings. In case there are multiple equally likely words return all of them.\n",
        "Note that you do not have to loop over the entire vocabulary to obtain the most likely word.\n",
        "\n",
        "## d) Generating text using markov model\n",
        "\n",
        "Write a funciton `generate_text(self, past, n)` that generates text given a starting sequence of words (`past`). It generates text by always choosing the most likely next word. It returns a list of strings. The list is of length `n`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZiHOiSYH7mk"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "class MarkovModel():\n",
        "    def __init__(self, corpus, order, laplace=0):\n",
        "        self.laplace = laplace\n",
        "        self.order = order\n",
        "        self.counts, self.v = self.process_corpus(corpus)\n",
        "\n",
        "    def process_corpus(self, corpus):\n",
        "        counts = defaultdict(Counter)\n",
        "        for i in range(len(corpus) - self.order):\n",
        "            past = []\n",
        "            for j in range(0, self.order):\n",
        "                past.append(corpus[i+j])\n",
        "\n",
        "            past = tuple(past)\n",
        "            if (past not in counts):\n",
        "                counts[past] = Counter()\n",
        "\n",
        "            counts[past][corpus[i+self.order]] += 1\n",
        "\n",
        "        return counts, set(get_valid_tokens(corpus))\n",
        "\n",
        "    def transition_prob(self, past, word):\n",
        "        if word not in self.counts:\n",
        "            return 1/len(self.v)\n",
        "        words = self.counts[past]\n",
        "\n",
        "\n",
        "        sum_all_counts = 0\n",
        "        for el in words.elements():\n",
        "            #print(el, words[el])\n",
        "            sum_all_counts += 1\n",
        "\n",
        "        return (words[word] + 1*self.laplace)/(sum_all_counts + len(self.v)*self.laplace)\n",
        "\n",
        "    def most_likely_word(self, past):\n",
        "        most_likely = self.counts[past].most_common()\n",
        "        val = most_likely[0][1]\n",
        "        ret = []\n",
        "        i = 0\n",
        "        loop = True\n",
        "        while (loop):\n",
        "            if i < len(most_likely) and most_likely[i][1] == val:\n",
        "                ret.append(most_likely[i][0])\n",
        "                i += 1\n",
        "            else:\n",
        "                loop = False\n",
        "\n",
        "        return ret\n",
        "\n",
        "    def generate_text(self, past, n):\n",
        "        text = list(past)\n",
        "        for i in range(n - len(past)):\n",
        "            next_word = self.most_likely_word(past)[0]\n",
        "            text.append(next_word)\n",
        "\n",
        "            past_list = list(past)\n",
        "            past_list.pop(0)\n",
        "            past_list.append(next_word)\n",
        "            past = tuple(past_list)\n",
        "        return text\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OggO0OsRH7mk",
        "outputId": "00b9bd58-61d0-4ab5-b15b-b6f5ddc388f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'you', 'how', 'are', 'james', 'hello', 'hi', 'catherine'}\n",
            "defaultdict(<class 'collections.Counter'>, {('hi',): Counter({'james': 1}), ('james',): Counter({'how': 1}), ('how',): Counter({'are': 2}), ('are',): Counter({'you': 2}), ('you',): Counter({'hello': 1}), ('hello',): Counter({'catherine': 1}), ('catherine',): Counter({'how': 1})})\n"
          ]
        }
      ],
      "source": [
        "mm = MarkovModel(get_valid_tokens(simple_text),1)\n",
        "print(mm.v) # {'how', 'hi', 'you', 'hello', 'james', 'are', 'catherine'}\n",
        "print(mm.counts)\n",
        "#{('hi',): Counter({'james': 1}), ('james',): Counter({'how': 1}), ('how',): Counter({'are': 2}), ('are',): Counter({'you': 2}), ('you',): Counter({'hello': 1}), ('hello',): Counter({'catherine': 1}), ('catherine',): Counter({'how': 1})}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WqOy5Z2H7ml",
        "outputId": "d88bfdb5-edeb-42a9-d48d-41863b8f6a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'you', 'how', 'are', 'james', 'hello', 'hi', 'catherine'}\n",
            "defaultdict(<class 'collections.Counter'>, {('hi', 'james'): Counter({'how': 1}), ('james', 'how'): Counter({'are': 1}), ('how', 'are'): Counter({'you': 2}), ('are', 'you'): Counter({'hello': 1}), ('you', 'hello'): Counter({'catherine': 1}), ('hello', 'catherine'): Counter({'how': 1}), ('catherine', 'how'): Counter({'are': 1})})\n"
          ]
        }
      ],
      "source": [
        "mm = MarkovModel(get_valid_tokens(simple_text),2)\n",
        "print(mm.v) # {'how', 'hi', 'you', 'hello', 'james', 'are', 'catherine'}\n",
        "print(mm.counts)\n",
        "# {('hi', 'james'): Counter({'how': 1}), ('james', 'how'): Counter({'are': 1}), ('how', 'are'): Counter({'you': 2}), ('are', 'you'): Counter({'hello': 1}), ('you', 'hello'): Counter({'catherine': 1}), ('hello', 'catherine'): Counter({'how': 1}), ('catherine', 'how'): Counter({'are': 1})}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXvAynoAH7ml"
      },
      "outputs": [],
      "source": [
        "# now applied to the bible dataset\n",
        "tokens = get_valid_tokens(nltk.corpus.gutenberg.words('bible-kjv.txt'), remove_stopwords=False)\n",
        "m=MarkovModel(tokens, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YutTmnfGH7ml",
        "outputId": "5158b4aa-ce61-4c47-a810-16ba5711ca5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7.949757532395262e-05"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.transition_prob(('in', 'the'), 'beginning')\n",
        "# 0.003379049890677798"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48RZtZktH7ml",
        "outputId": "39e1542d-8893-4320-bed2-7ed0e79f3ad7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7.949757532395262e-05"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.transition_prob(('in', 'the'), 'land')\n",
        "# 0.06440071556350627"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSbUqyjBH7ml",
        "outputId": "a2f6bd0e-caf8-420d-b0b7-889f7ee975bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['no']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.most_likely_word(('there', 'is'))\n",
        "# ['no']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8ro3ZlUH7ml"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rKU7MwfH7ml"
      },
      "outputs": [],
      "source": [
        "tokens = get_valid_tokens(nltk.corpus.gutenberg.words('bible-kjv.txt'), remove_stopwords=False)\n",
        "m=MarkovModel(tokens, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1E5GKXENH7ml",
        "outputId": "e44c13bc-4c56-417f-aeb1-ae10897a166d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['with']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.most_likely_word(('the', 'lord', 'is')) # ['with']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR811v4MH7mm",
        "outputId": "470a0bb6-5c2a-4ae4-9eaf-1fe780b8586d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['we', 'are', 'here', 'in', 'a', 'desert', 'land', 'and', 'in', 'the', 'days', 'of', 'his', 'life', 'and', 'the', 'life', 'of', 'the', 'flesh', 'of', 'the', 'sacrifice', 'of', 'the', 'peace', 'offerings', 'and', 'the', 'priest']\n"
          ]
        }
      ],
      "source": [
        "print(m.generate_text(('we', 'are', 'here'), 30))\n",
        "# ['we', 'are', 'here', 'in', 'a', 'desert', 'land', 'and', 'in', 'the', 'days', 'of', 'his', 'life', 'and', 'the', 'life', 'of', 'the', 'flesh', 'of', 'the', 'sacrifice', 'of', 'the', 'peace', 'offerings', 'and', 'the', 'priest']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxiwgVtLH7mm",
        "outputId": "b3d935e2-ff7f-4d15-d5c8-06680bd8c6d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['the', 'lord', 'is', 'with', 'thee', 'and', 'thou', 'shalt', 'make', 'the', 'staves', 'of', 'shittim', 'wood', 'and', 'overlay', 'them', 'with', 'gold', 'and']\n"
          ]
        }
      ],
      "source": [
        "print(m.generate_text(('the', 'lord', 'is'),20))\n",
        "# ['the', 'lord', 'is', 'with', 'thee', 'and', 'thou', 'shalt', 'make', 'the', 'staves', 'of', 'shittim', 'wood', 'and', 'overlay', 'them', 'with', 'gold', 'and']"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}